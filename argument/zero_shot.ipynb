{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Extracting Argument Premises Using Zero-Shot Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "This notebook applies zero-shot prompting to extract argument premises from the data entries.\n",
    "There are two prompts: zero-shot and zero-shot chain-of-thought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T22:08:55.190176700Z",
     "start_time": "2024-06-22T22:08:55.000319100Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from OllamaCached import llm_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T22:08:55.195105100Z",
     "start_time": "2024-06-22T22:08:55.192603700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# setting environment variables for OllamaCached model\n",
    "os.environ[\"OLLAMA_MODELS\"] = \"./models\"\n",
    "os.environ[\"OLLAMA_KEEP_ALIVE\"] = \"1m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T22:08:55.201482800Z",
     "start_time": "2024-06-22T22:08:55.195105100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# list of policy options associated with the data entries\n",
    "policy_option_list = ['The municipality takes the lead and unburdens you',\n",
    "                      'Inhabitants do it themselves',\n",
    "                      'The market determines what is coming',\n",
    "                      'Large-scale energy generation will occur in a small number of places',\n",
    "                      'Betting on storage (Sudwest-Fryslan becomes the battery of the Netherlands)',\n",
    "                      'Become a major energy supplier in the Netherlands']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T22:08:55.211616300Z",
     "start_time": "2024-06-22T22:08:55.201482800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "annotator_number = 1\n",
    "file_path = f'data_extraction/personal_annotation_{annotator_number}.json'\n",
    "\n",
    "# load data\n",
    "with open(file_path, 'r') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T22:09:46.080609300Z",
     "start_time": "2024-06-22T22:08:55.213611700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# path for saving the results\n",
    "file_path = f'llm_responses/zero_shot_cot.json'\n",
    "os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "\n",
    "number_of_trials = 10 # adjust as needed\n",
    "trial_collection = []\n",
    "\n",
    "for i in range (0, number_of_trials):\n",
    "    print(f\"Run number {i + 1}\")\n",
    "    output_collection = []\n",
    "    for i, argument in enumerate(tqdm(data.get('english_text'), desc='Processing arguments', unit = 'argument')):\n",
    "\n",
    "        # zero-shot prompt\n",
    "        zero_shot_prompt = [\n",
    "            {'role': 'system', 'content': f'''You are an expert in identifying arguments and their premises in a text. An argument is a set of claims in which one or more of them—the premises—are put forward so as to offer reasons for another claim, the conclusion. A text that does not provide support or reasons for a conclusion is not an argument.'''},\n",
    "            {'role': 'user', 'content': f'''You know that the text is related to this conclusion: {policy_option_list[data.get('question_id')[i] - 1]}. Can you extract the words in this sentence that state the premise or premises of this text: {argument} or extract \"None\" if the text is not an argument.\n",
    "\n",
    "            Return the following JSON with the premises found in the text:\n",
    "            {{\n",
    "                \"premise_1\": \"\",\n",
    "                ...\n",
    "            }}. '''}\n",
    "        ]\n",
    "\n",
    "        # zero-shot chain-of-thought prompt\n",
    "        zero_shot_cot_prompt = [\n",
    "            {'role': 'system', 'content': '''You are an expert in identifying arguments and their premises in a text. An argument is a set of claims in which one or more of them—the premises—are put forward so as to offer reasons for another claim, the conclusion. A text that does not provide support or reasons for a conclusion is not an argument.'''},\n",
    "            {'role': 'user', 'content': f'''Let's think step by step. You know that the text is related to this conclusion: {policy_option_list[data.get('question_id')[i] - 1]}. Can you extract the words in this sentence that state the premise or premises of this text: {argument} or extract \"None\" if the text is not an argument.\n",
    "             Step 1, determine if the text provides any support or reasons for the conclusion. If it does not provide support or reasons for the conclusion, return {{\"premise_1\": \"None\"}} and don't execute the next steps.\n",
    "             Step 2, If it does provide support or reasons, return the following JSON with the premises found in the text:\n",
    "            {{\n",
    "                \"premise_1\": \"\",\n",
    "                ...\n",
    "            }}.\n",
    "             '''}]\n",
    "\n",
    "        # adjust prompt message as needed\n",
    "        output = llm_chat(model_name='llama2:latest',\n",
    "                           message=zero_shot_cot_prompt)\n",
    "\n",
    "        output_collection.append(output)\n",
    "        print(output)\n",
    "    trial_collection.append(output_collection)\n",
    "\n",
    "# save results\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(trial_collection, json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
