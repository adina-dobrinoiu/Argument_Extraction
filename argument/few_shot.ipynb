{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Extracting Argument Premises Using Few-Shot Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "This notebook applies few-shot prompting to extract argument premises from the data entries.\n",
    "There are two prompts: few-shot and few-shot chain-of-thought.\n",
    "There are two types of labels: individual annotator labels and majority vote labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T22:35:22.818486500Z",
     "start_time": "2024-06-22T22:35:22.502488Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from OllamaCached import llm_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T22:35:22.818486500Z",
     "start_time": "2024-06-22T22:35:22.655927200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# setting environment variables for OllamaCached model\n",
    "os.environ[\"OLLAMA_MODELS\"] = \"./models\"\n",
    "os.environ[\"OLLAMA_KEEP_ALIVE\"] = \"1m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T22:35:22.818486500Z",
     "start_time": "2024-06-22T22:35:22.659993400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# list of policy options associated with the data entries\n",
    "policy_option_list = ['The municipality takes the lead and unburdens you',\n",
    "                      'Inhabitants do it themselves',\n",
    "                      'The market determines what is coming',\n",
    "                      'Large-scale energy generation will occur in a small number of places',\n",
    "                      'Betting on storage (Sudwest-Fryslan becomes the battery of the Netherlands)',\n",
    "                      'Become a major energy supplier in the Netherlands']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T22:35:22.818486500Z",
     "start_time": "2024-06-22T22:35:22.664183100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# extract the required data per annotator\n",
    "def extract_data_per_annotator(annotator_number):\n",
    "    file_path = f'data_extraction/personal_annotation_{annotator_number}.json'\n",
    "\n",
    "    with open(file_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T22:35:22.818486500Z",
     "start_time": "2024-06-22T22:35:22.669061700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def apply_few_shot_per_annotator(annotator_number, data, training_example_1, training_example_2, training_example_3):\n",
    "    \"\"\"\n",
    "    Applies few-shot prompting per individual annotator.\n",
    "    Args:\n",
    "        annotator_number: number of annotator\n",
    "        data: required data\n",
    "        training_example_1: first training example used\n",
    "        training_example_2: second training example used\n",
    "        training_example_3: third training example used\n",
    "\n",
    "    Returns: saves the results to location 'llm_responses/one_shot_majority_vote.json'\n",
    "\n",
    "    \"\"\"\n",
    "    # path for saving the result\n",
    "    file_path = f'llm_responses/few_shot_majority_vote.json'\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "\n",
    "    number_of_trials = 10 # adjust as needed\n",
    "    trial_collection = []\n",
    "\n",
    "    for i in range (0, number_of_trials):\n",
    "        print(f\"Run number {i + 1}\")\n",
    "        output_collection = []\n",
    "        for i, argument in enumerate(tqdm(data.get('english_text'), desc='Processing arguments', unit = 'argument')):\n",
    "\n",
    "            # few-shot prompt\n",
    "            few_shot_prompt = [\n",
    "            {'role': 'system', 'content': f'''You are an expert in identifying arguments and their premises in a text. An argument is a set of claims in which one or more of them—the premises—are put forward so as to offer reasons for another claim, the conclusion. A text that does not provide support or reasons for a conclusion is not an argument. {training_example_1} {training_example_2} {training_example_3}'''},\n",
    "            {'role': 'user', 'content': f'''You know that the text is related to this conclusion: {policy_option_list[data.get('question_id')[i] - 1]}. Can you extract the words in this sentence that state the premise or premises of this text: {argument} or extract \"None\" if the text is not an argument.\n",
    "\n",
    "            Return the following JSON with the premises found in the text:\n",
    "            {{\n",
    "                \"premise_1\": \"\",\n",
    "                ...\n",
    "            }}. '''}]\n",
    "\n",
    "            # few-shot chain-of-thought prompt\n",
    "            few_shot_cot_prompt = [\n",
    "            {'role': 'system', 'content': f'''You are an expert in identifying arguments and their premises in a text. An argument is a set of claims in which one or more of them—the premises—are put forward so as to offer reasons for another claim, the conclusion. A text that does not provide support or reasons for a conclusion is not an argument.'''},\n",
    "            {'role': 'user', 'content': f'''Here are some examples to illustrate the task: {training_example_1} {training_example_2} {training_example_3}\n",
    "             Now, let's move to the actual task.'''},\n",
    "            {'role': 'user', 'content': f'''Let's think step by step. You know that the text is related to this conclusion: {policy_option_list[data.get('question_id')[i] - 1]}. Can you extract the words in this sentence that state the premise or premises of this text: {argument} or extract \"None\" if the text is not an argument.\n",
    "             Step 1, determine if the text provides any support or reasons for the conclusion. If it does not provide support or reasons for the conclusion, return {{\"premise_1\": \"None\"}} and don't execute the next steps.\n",
    "             Step 2, If it does provide support or reasons, return the following JSON with the premises found in the text:\n",
    "            {{\n",
    "                \"premise_1\": \"\",\n",
    "                ...\n",
    "            }}.\n",
    "             '''}]\n",
    "\n",
    "            # adjust prompt message as needed\n",
    "            output = llm_chat(model_name='llama2:latest',\n",
    "                               message=few_shot_cot_prompt)\n",
    "\n",
    "            output_collection.append(output)\n",
    "            print(output)\n",
    "        trial_collection.append(output_collection)\n",
    "\n",
    "    with open(file_path, 'w') as json_file:\n",
    "        json.dump(trial_collection, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T22:35:22.818486500Z",
     "start_time": "2024-06-22T22:35:22.677292800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# training example for few-shot method\n",
    "# it is personalized to the annotated data of this research\n",
    "# if data is annotated differently, this method may be subject to change\n",
    "def create_training_example_1(annotator_number):\n",
    "    if annotator_number == 2:\n",
    "        return f\"An example for this task is for input : {data.get('english_text')[0]}, the output is: {{'premise_1': {data.get('labels')[0][0]}}}.\"\n",
    "\n",
    "    return f\"An example for this task is for input : {data.get('english_text')[0]}, the output is: {{'premise_1': {data.get('labels')[0][0]}, 'premise_2': {data.get('labels')[0][1]}}}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T22:35:22.818486500Z",
     "start_time": "2024-06-22T22:35:22.681192100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# training example for few-shot method\n",
    "# it is personalized to the annotated data of this research\n",
    "# if data is annotated differently, this method may be subject to change\n",
    "def create_training_example_2():\n",
    "    return f\"Another example for this task is for input : {data.get('english_text')[3]}, the output is: {{'premise_1': {data.get('labels')[3][0]}}}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T22:35:22.818486500Z",
     "start_time": "2024-06-22T22:35:22.686283500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# training example for few-shot method\n",
    "# it is personalized to the annotated data of this research\n",
    "# if data is annotated differently, this method may be subject to change\n",
    "def create_training_example_3():\n",
    "    return f\"Another example for this task is for input : {data.get('english_text')[12]}, the output is: {{'premise_1': {data.get('labels')[12][0]}}}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T22:35:22.818486500Z",
     "start_time": "2024-06-22T22:35:22.690835400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# training example for few-shot chain-of-thought method\n",
    "# it is personalized to the annotated data of this research\n",
    "# if data is annotated differently, this method may be subject to change\n",
    "def create_cot_training_example_1(annotator_number):\n",
    "    if annotator_number == 2:\n",
    "        return f\"An example for this is for input: {data.get('english_text')[0]}:\" \\\n",
    "               f\"Step 1: the text does provide support or reasons for the conclusion. Therefore, execute the next step.\" \\\n",
    "               f\"Step 2: return output: {{'premise_1': {data.get('labels')[0][0]}}}.\" \\\n",
    "\n",
    "    return f\"An example for this is for input: {data.get('english_text')[0]}:\" \\\n",
    "               f\"Step 1: the text does provide support or reasons for the conclusion. Therefore, execute the next step.\" \\\n",
    "               f\"Step 2: return output: {{'premise_1': {data.get('labels')[0][0]}, 'premise_2': {data.get('labels')[0][1]}}}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T22:35:22.818486500Z",
     "start_time": "2024-06-22T22:35:22.694905300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# training example for few-shot chain-of-thought method\n",
    "# it is personalized to the annotated data of this research\n",
    "# if data is annotated differently, this method may be subject to change\n",
    "def create_cot_training_example_2(annotator_number):\n",
    "    if annotator_number == 2 or annotator_number == 3 or annotator_number == 5:\n",
    "        return f\"Another example for this is for input: {data.get('english_text')[3]}:\" \\\n",
    "               f\"Step 1: the text does not provide support or reasons for the conclusion. Therefore, do not execute the next step.\" \\\n",
    "               f\"Return output: {{'premise_1': {data.get('labels')[3][0]}}}\" \\\n",
    "\n",
    "    return f\"An example for this is for input: {data.get('english_text')[3]}:\" \\\n",
    "               f\"Step 1: the text does provide support or reasons for the conclusion. Therefore, execute the next step.\" \\\n",
    "               f\"Step 2: return output: {{'premise_1': {data.get('labels')[3][0]}}}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T22:35:22.818486500Z",
     "start_time": "2024-06-22T22:35:22.699870Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# training example for few-shot chain-of-thought method\n",
    "# it is personalized to the annotated data of this research\n",
    "# if data is annotated differently, this method may be subject to change\n",
    "def create_cot_training_example_3():\n",
    "    return f\"Another example for this is for input: {data.get('english_text')[12]}:\" \\\n",
    "           f\"Step 1: the text does not provide support or reasons for the conclusion. Therefore, do not execute the next step.\" \\\n",
    "           f\"Return output: {{'premise_1': {data.get('labels')[12][0]}}}.\" \\\n",
    "           f\"Now apply similar logic to other examples.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T22:35:22.895296800Z",
     "start_time": "2024-06-22T22:35:22.703597300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# training example for few-shot chain-of-thought majority vote labels method\n",
    "# it is personalized to the annotated data of this research\n",
    "# if data is annotated differently, this method may be subject to change\n",
    "%run aggregate_labels.ipynb\n",
    "def create_majority_vote_training_example_1():\n",
    "    aggregated_data = get_majority_vote_labels_dataset()\n",
    "    return f\"An example for this is for input: '{data.get('english_text')[0]}': \" \\\n",
    "               f\"Step 1: the text does provide support or reasons for the conclusion. Therefore, execute the next step. \" \\\n",
    "               f\"Step 2: return output: {{'premise_1': '{aggregated_data[0][0]}', 'premise_2': '{aggregated_data[0][1]}'}} .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T22:35:22.908176900Z",
     "start_time": "2024-06-22T22:35:22.895296800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# training example for few-shot chain-of-thought majority vote labels method\n",
    "# it is personalized to the annotated data of this research\n",
    "# if data is annotated differently, this method may be subject to change\n",
    "%run aggregate_labels.ipynb\n",
    "def create_majority_vote_training_example_2():\n",
    "    aggregated_data = get_majority_vote_labels_dataset()\n",
    "    return f\"Another example for this is for input: '{data.get('english_text')[3]}': \" \\\n",
    "           f\"Step 1: the text does not provide support or reasons for the conclusion. Therefore, do not execute the next step. \" \\\n",
    "           f\"Return output: {{'premise_1': '{aggregated_data[3][0]}'}}. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T22:35:22.922220500Z",
     "start_time": "2024-06-22T22:35:22.908176900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# training example for few-shot chain-of-thought majority vote labels method\n",
    "# it is personalized to the annotated data of this research\n",
    "# if data is annotated differently, this method may be subject to change\n",
    "%run aggregate_labels.ipynb\n",
    "def create_majority_vote_training_example_3():\n",
    "    aggregated_data = get_majority_vote_labels_dataset()\n",
    "    return f\"Another example for this is for input: '{data.get('english_text')[12]}': \" \\\n",
    "           f\"Step 1: the text does not provide support or reasons for the conclusion. Therefore, do not execute the next step. \" \\\n",
    "           f\"Return output: {{'premise_1': '{aggregated_data[12][0]}'}} \" \\\n",
    "           f\"Now apply similar logic to other examples. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T22:36:03.952728900Z",
     "start_time": "2024-06-22T22:35:22.922220500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# compute few-shot results for each of annotator\n",
    "for i in range(0, 1):\n",
    "    data = extract_data_per_annotator(i + 1)\n",
    "    argument_data = list(data.get(\"english_text\"))\n",
    "    labels = list(data.get(\"labels\"))\n",
    "\n",
    "    # few-shot training examples\n",
    "    training_example_1 = create_training_example_1(i + 1)\n",
    "    training_example_2 = create_training_example_2()\n",
    "    training_example_3 = create_training_example_3()\n",
    "\n",
    "    # few-shot chain-of-thought training examples\n",
    "    cot_training_example_1 = create_cot_training_example_1(i + 1)\n",
    "    cot_training_example_2 = create_cot_training_example_2(i + 1)\n",
    "    cot_training_example_3 = create_cot_training_example_3()\n",
    "\n",
    "    # few-shot chain-of-thought training examples\n",
    "    majority_vote_training_example_1 = create_majority_vote_training_example_1()\n",
    "    majority_vote_training_example_2 = create_majority_vote_training_example_2()\n",
    "    majority_vote_training_example_3 = create_majority_vote_training_example_3()\n",
    "\n",
    "    # adjust training examples as needed\n",
    "    apply_few_shot_per_annotator(i + 1, data, majority_vote_training_example_1, majority_vote_training_example_2, majority_vote_training_example_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
