{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T10:51:29.005827700Z",
     "start_time": "2024-06-23T10:51:28.920061900Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-06-23T10:51:29.248339500Z",
     "start_time": "2024-06-23T10:51:29.246836600Z"
    }
   },
   "outputs": [],
   "source": [
    "# get required data per annotator\n",
    "def extract_data_per_annotator(annotator_number):\n",
    "    file_path = f'data_extraction/personal_annotation_{annotator_number}.json'\n",
    "\n",
    "    with open(file_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-06-23T10:51:29.924591900Z",
     "start_time": "2024-06-23T10:51:29.916377100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 35, 13, 18, 22]\n"
     ]
    }
   ],
   "source": [
    "# outputs how many data items each annotator labelled as \"None\"\n",
    "def output_number_of_none_arguments_per_annotator():\n",
    "    annotators_none_values = []\n",
    "    for i in range(0, 5):\n",
    "        annotator_none_values = 0\n",
    "        data = extract_data_per_annotator(i + 1).get(\"labels\")\n",
    "\n",
    "        for entry in data:\n",
    "            if 'None' in entry:\n",
    "                annotator_none_values += 1\n",
    "        annotators_none_values.append(annotator_none_values)\n",
    "\n",
    "    return annotators_none_values\n",
    "\n",
    "print(output_number_of_none_arguments_per_annotator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-06-23T10:52:07.135268200Z",
     "start_time": "2024-06-23T10:52:07.107664500Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from itertools import combinations\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Tokenizes the text into words and returns a list of tokens.\n",
    "    \"\"\"\n",
    "    return text.split()\n",
    "\n",
    "def span_to_token_set(span, text):\n",
    "    \"\"\"\n",
    "    Converts a text span into a set of token positions.\n",
    "    \"\"\"\n",
    "    tokens = tokenize(text)\n",
    "    span_tokens = tokenize(span)\n",
    "    token_positions = {i for i, token in enumerate(tokens) if token in span_tokens}\n",
    "    return token_positions\n",
    "\n",
    "def precision_recall_f1(set1, set2):\n",
    "    \"\"\"\n",
    "    Calculates precision, recall, and F1 score between two sets of tokens.\n",
    "    \"\"\"\n",
    "    true_positive = len(set1 & set2)\n",
    "    false_positive = len(set1 - set2)\n",
    "    false_negative = len(set2 - set1)\n",
    "\n",
    "    precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
    "    recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "def average_f1_score(data, text):\n",
    "    \"\"\"\n",
    "    Calculates the average F1 score for overlapping spans in the dataset.\n",
    "    \"\"\"\n",
    "    total_f1 = 0\n",
    "    count = 0\n",
    "    for annotations in data:\n",
    "        pairwise_f1 = []\n",
    "        for (a, b) in combinations(annotations, 2):\n",
    "            token_set_a = set().union(*[span_to_token_set(span, text) for span in a])\n",
    "            token_set_b = set().union(*[span_to_token_set(span, text) for span in b])\n",
    "            _, _, f1 = precision_recall_f1(token_set_a, token_set_b)\n",
    "            pairwise_f1.append(f1)\n",
    "        total_f1 += sum(pairwise_f1)\n",
    "        count += len(pairwise_f1)\n",
    "    return total_f1 / count if count > 0 else 0\n",
    "\n",
    "\n",
    "number_of_annotations = 50 # change as needed\n",
    "annotation_cumulative = []\n",
    "for i in range(0, number_of_annotations):\n",
    "    current_annotations = []\n",
    "    for j in range (0, 5):\n",
    "        if j == 0 or j == 2 or j == 1:\n",
    "            continue\n",
    "        data = extract_data_per_annotator(j + 1).get(\"labels\")\n",
    "        current_annotations.append(data[i])\n",
    "    annotation_cumulative.append(current_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-06-23T10:52:17.839753600Z",
     "start_time": "2024-06-23T10:52:17.830230300Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-06-23T10:52:18.439070200Z",
     "start_time": "2024-06-23T10:52:18.429094600Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_data_per_annotator(annotator_number):\n",
    "    file_path = f'data_extraction/personal_annotation_{annotator_number}.json'\n",
    "\n",
    "    with open(file_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-06-23T10:52:19.400902200Z",
     "start_time": "2024-06-23T10:52:19.210763800Z"
    }
   },
   "outputs": [],
   "source": [
    "%run process_answer.ipynb\n",
    "\n",
    "def get_data(llm_method, annotator_1, annotator_2):\n",
    "    # annotator_data = extract_data_per_annotator(annotator_number)\n",
    "    llm_result_1 = process_and_store_llm_answers(f'llm_responses/{llm_method}_{annotator_1}.json')\n",
    "    llm_result_2 = process_and_store_llm_answers(f'llm_responses/{llm_method}_{annotator_2}.json')\n",
    "\n",
    "    return llm_result_1, llm_result_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-06-23T11:09:16.653967100Z",
     "start_time": "2024-06-23T11:09:16.650468200Z"
    }
   },
   "outputs": [],
   "source": [
    "# pairwise cot\n",
    "def compute_cosine_similarity(number_of_entries, samples_used_for_training, llm_method, annotator_1, annotator_2):\n",
    "    dataset_average_cosine_similarity = 0\n",
    "    llm_result_1, llm_result_2 = get_data(llm_method, annotator_1, annotator_2)\n",
    "\n",
    "    average_similarity_all_runs = 0\n",
    "    for j in range(0, 10):\n",
    "        for i in range(0, number_of_entries):\n",
    "            if i in samples_used_for_training:\n",
    "                continue\n",
    "\n",
    "            # llm response\n",
    "            c = llm_result_1[j][i]\n",
    "            if len(c) == 0:\n",
    "                c.append('None')\n",
    "\n",
    "            if len(c) >= 2:\n",
    "                for response in c:\n",
    "                    if response == \"None\" or response == \"\":\n",
    "                        c.remove(response)\n",
    "\n",
    "            d = llm_result_2[j][i]\n",
    "            if len(d) == 0:\n",
    "                d.append('None')\n",
    "\n",
    "            if len(d) >= 2:\n",
    "                for response in d:\n",
    "                    if response == \"None\" or response == \"\":\n",
    "                        d.remove(response)\n",
    "\n",
    "\n",
    "            vectorizer = TfidfVectorizer().fit(c + d)\n",
    "            tfidf_c = vectorizer.transform(c)\n",
    "            tfidf_d = vectorizer.transform(d)\n",
    "\n",
    "            similarity_matrix = cosine_similarity(tfidf_c, tfidf_d)\n",
    "\n",
    "            # adjust similarities and compute the highest value for each row\n",
    "            similarity_sum = 0\n",
    "            for i, row in enumerate(similarity_matrix):\n",
    "                adjusted_row = [sim if sim >= 0.2 else 0 for sim in row]\n",
    "                highest_similarity = max(adjusted_row)\n",
    "                similarity_sum += highest_similarity\n",
    "\n",
    "\n",
    "\n",
    "            average_similarity = np.round(similarity_sum/(len(c)), 5)\n",
    "            dataset_average_cosine_similarity += average_similarity\n",
    "\n",
    "\n",
    "        dataset_average_cosine_similarity = np.round(dataset_average_cosine_similarity/(number_of_entries - len(set(samples_used_for_training))), 3)\n",
    "        average_similarity_all_runs += dataset_average_cosine_similarity\n",
    "\n",
    "    average_similarity_all_runs = np.round(average_similarity_all_runs/10, 2)\n",
    "    return average_similarity_all_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-06-23T11:09:26.180722300Z",
     "start_time": "2024-06-23T11:09:17.193830500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0.56, 0.71, 0.71, 0.69]\n",
      "[0, 1, 0.6, 0.59, 0.6]\n",
      "[0, 0, 1, 0.68, 0.68]\n",
      "[0, 0, 0, 1, 0.69]\n",
      "[0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# one shot cot\n",
    "def one_shot_cot():\n",
    "    number_of_entries = 50\n",
    "    samples_used_for_training = [0]\n",
    "    llm_method = 'one_shot_cot'\n",
    "\n",
    "    cumulative_cosine_similarity = []\n",
    "    for i in range(0, 5):\n",
    "        current_annotator_cosine_similarity = []\n",
    "        for j in range(0, 5):\n",
    "            if j > i:\n",
    "                current_annotator_cosine_similarity.append(compute_cosine_similarity(number_of_entries, samples_used_for_training, f'{llm_method}', i + 1, j + 1))\n",
    "            elif i == j:\n",
    "                current_annotator_cosine_similarity.append(1)\n",
    "            else:\n",
    "                current_annotator_cosine_similarity.append(0)\n",
    "\n",
    "        cumulative_cosine_similarity.append(current_annotator_cosine_similarity)\n",
    "\n",
    "    return cumulative_cosine_similarity\n",
    "\n",
    "result = one_shot_cot()\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-06-23T11:09:34.722952300Z",
     "start_time": "2024-06-23T11:09:26.184759400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0.39, 0.57, 0.65, 0.64]\n",
      "[0, 1, 0.42, 0.43, 0.43]\n",
      "[0, 0, 1, 0.58, 0.61]\n",
      "[0, 0, 0, 1, 0.64]\n",
      "[0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "def few_shot_cot():\n",
    "    number_of_entries = 50\n",
    "    samples_used_for_training = [0, 3, 12]\n",
    "    llm_method = 'few_shot_cot'\n",
    "\n",
    "    cumulative_cosine_similarity = []\n",
    "    for i in range(0, 5):\n",
    "        current_annotator_cosine_similarity = []\n",
    "        for j in range(0, 5):\n",
    "            if j > i:\n",
    "                current_annotator_cosine_similarity.append(compute_cosine_similarity(number_of_entries, samples_used_for_training, f'{llm_method}', i + 1, j + 1))\n",
    "            elif i == j:\n",
    "                current_annotator_cosine_similarity.append(1)\n",
    "            else:\n",
    "                current_annotator_cosine_similarity.append(0)\n",
    "\n",
    "        cumulative_cosine_similarity.append(current_annotator_cosine_similarity)\n",
    "\n",
    "    return cumulative_cosine_similarity\n",
    "\n",
    "result = few_shot_cot()\n",
    "for row in result:\n",
    "    print(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
