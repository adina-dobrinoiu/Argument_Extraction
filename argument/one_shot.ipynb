{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Extracting Argument Premises Using One-Shot Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "This notebook applies one-shot prompting to extract argument premises from the data entries.\n",
    "There are two prompts: one-shot and one-shot chain-of-thought.\n",
    "There are two types of labels: individual annotator labels and majority vote labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T23:12:58.840214100Z",
     "start_time": "2024-06-22T23:12:58.668553Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from OllamaCached import llm_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T23:12:58.845419800Z",
     "start_time": "2024-06-22T23:12:58.842210100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# setting environment variables for OllamaCached model\n",
    "os.environ[\"OLLAMA_MODELS\"] = \"./models\"\n",
    "os.environ[\"OLLAMA_KEEP_ALIVE\"] = \"1m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T23:12:58.850260400Z",
     "start_time": "2024-06-22T23:12:58.846417400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# list of policy options associated with the data entries\n",
    "policy_option_list = ['The municipality takes the lead and unburdens you',\n",
    "                      'Inhabitants do it themselves',\n",
    "                      'The market determines what is coming',\n",
    "                      'Large-scale energy generation will occur in a small number of places',\n",
    "                      'Betting on storage (Sudwest-Fryslan becomes the battery of the Netherlands)',\n",
    "                      'Become a major energy supplier in the Netherlands']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T23:12:58.854393200Z",
     "start_time": "2024-06-22T23:12:58.851258900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# extract the required data per annotator\n",
    "def extract_data_per_annotator(annotator_number):\n",
    "    file_path = f'data_extraction/personal_annotation_{annotator_number}.json'\n",
    "\n",
    "    with open(file_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T23:12:58.863111700Z",
     "start_time": "2024-06-22T23:12:58.855390900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def apply_one_shot_per_annotator(annotator_number, data, training_example):\n",
    "    \"\"\"\n",
    "    Applies one-shot prompting per individual annotator.\n",
    "    Args:\n",
    "        annotator_number: number of annotator\n",
    "        data: required data\n",
    "        training_example: training example used\n",
    "\n",
    "    Returns: saves the results to location 'llm_responses/one_shot_majority_vote.json'\n",
    "\n",
    "    \"\"\"\n",
    "    # path for saving the result\n",
    "    file_path = f'llm_responses/one_shot_majority_vote.json'\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "\n",
    "    number_of_trials = 10 # adjust as needed\n",
    "    trial_collection = []\n",
    "\n",
    "    for i in range (0, number_of_trials):\n",
    "        print(f\"Run number {i + 1}\")\n",
    "        output_collection = []\n",
    "        for i, argument in enumerate(tqdm(data.get('english_text'), desc='Processing arguments', unit = 'argument')):\n",
    "\n",
    "            # one-shot prompt\n",
    "            one_shot_prompt = [\n",
    "            {'role': 'system', 'content': f'''You are an expert in identifying arguments and their premises in a text. An argument is a set of claims in which one or more of them—the premises—are put forward so as to offer reasons for another claim, the conclusion. A text that does not provide support or reasons for a conclusion is not an argument. {training_example}'''},\n",
    "            {'role': 'user', 'content': f'''Can you extract the words in this sentence that state the premise or premises of this text: {argument} or extract \"None\" if the text is not an argument.\n",
    "\n",
    "            Return the following JSON with the premises found in the text:\n",
    "            {{\n",
    "                \"premise_1\": \"\",\n",
    "                ...\n",
    "            }}.'''}\n",
    "        ]\n",
    "\n",
    "            # one-shot chain-of-thought prompt\n",
    "            one_shot_cot_prompt = [\n",
    "            {'role': 'system', 'content': f'''You are an expert in identifying arguments and their premises in a text. An argument is a set of claims in which one or more of them—the premises—are put forward so as to offer reasons for another claim, the conclusion. A text that does not provide support or reasons for a conclusion is not an argument.'''},\n",
    "            {'role': 'user', 'content': f'''Here is an example to illustrate the task: {training_example}\n",
    "             Now, let's move to the actual task.'''},\n",
    "            {'role': 'user', 'content': f'''Let's think step by step. You know that the text is related to this conclusion: {policy_option_list[data.get('question_id')[i] - 1]}. Can you extract the words in this sentence that state the premise or premises of this text: {argument} or extract \"None\" if the text is not an argument.\n",
    "             Step 1, determine if the text provides any support or reasons for the conclusion. If it does not provide support or reasons for the conclusion, return {{\"premise_1\": \"None\"}} and don't execute the next steps.\n",
    "             Step 2, If it does provide support or reasons, return the following JSON with the premises found in the text:\n",
    "            {{\n",
    "                \"premise_1\": \"\",\n",
    "                ...\n",
    "            }}.\n",
    "             '''}]\n",
    "\n",
    "            # adjust prompt message as needed\n",
    "            output = llm_chat(model_name='llama2:latest',\n",
    "                               message=one_shot_cot_prompt)\n",
    "\n",
    "            output_collection.append(output)\n",
    "            print(output)\n",
    "        trial_collection.append(output_collection)\n",
    "\n",
    "    # save results\n",
    "    with open(file_path, 'w') as json_file:\n",
    "        json.dump(trial_collection, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T23:12:58.867280300Z",
     "start_time": "2024-06-22T23:12:58.864109300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# training example for one-shot method\n",
    "# it is personalized to the annotated data of this research\n",
    "# if data is annotated differently, this method may be subject to change\n",
    "def create_training_example(annotator_number):\n",
    "    if annotator_number == 2:\n",
    "        return f\"An example for this task is for input : {data.get('english_text')[0]}, the output is: {{'premise_1': {data.get('labels')[0][0]}}}.\"\n",
    "\n",
    "    return f\"An example for this task is for input : {data.get('english_text')[0]}, the output is: {{'premise_1': {data.get('labels')[0][0]}, 'premise_2': {data.get('labels')[0][1]}}}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T23:12:58.872418700Z",
     "start_time": "2024-06-22T23:12:58.869282300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# training example for one-shot chain-of-thought method\n",
    "# it is personalized to the annotated data of this research\n",
    "# if data is annotated differently, this method may be subject to change\n",
    "def create_cot_training_example(annotator_number):\n",
    "    if annotator_number == 2:\n",
    "        return f\"An example for this is for input: {data.get('english_text')[0]}:\" \\\n",
    "               f\"Step 1: the text does provide support or reasons for the conclusion. Therefore, execute the next step.\" \\\n",
    "               f\"Step 2: return output: {{'premise_1': {data.get('labels')[0][0]}}}.\" \\\n",
    "               f\"Now apply similar logic to other examples.\"\n",
    "\n",
    "    return f\"An example for this is for input: {data.get('english_text')[0]}:\" \\\n",
    "               f\"Step 1: the text does provide support or reasons for the conclusion. Therefore, execute the next step.\" \\\n",
    "               f\"Step 2: return output: {{'premise_1': {data.get('labels')[0][0]}, 'premise_2': {data.get('labels')[0][1]}}}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T23:12:59.075990900Z",
     "start_time": "2024-06-22T23:12:58.873417100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# training example for one-shot chain-of-thoughts majority vote labels method\n",
    "# it is personalized to the annotated data of this research\n",
    "# if data is annotated differently, this method may be subject to change\n",
    "%run aggregate_labels.ipynb\n",
    "def create_majority_vote_training_example():\n",
    "    # get majority vote labels\n",
    "    aggregated_data = get_majority_vote_labels_dataset()\n",
    "\n",
    "    return f\"An example for this is for input: {data.get('english_text')[0]}:\" \\\n",
    "               f\"Step 1: the text does provide support or reasons for the conclusion. Therefore, execute the next step.\" \\\n",
    "               f\"Step 2: return output: {{'premise_1': {aggregated_data[0][0]}, 'premise_2': {aggregated_data[0][1]}}}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T23:13:41.278171400Z",
     "start_time": "2024-06-22T23:12:59.076988900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# compute one-shot results for each of annotator\n",
    "for i in range(0, 5):\n",
    "    data = extract_data_per_annotator(i + 1)\n",
    "    argument_data = list(data.get(\"english_text\"))\n",
    "    labels = list(data.get(\"labels\"))\n",
    "\n",
    "    training_example = create_training_example(i + 1)\n",
    "    cot_training_example = create_cot_training_example(i + 1)\n",
    "    majority_vote_training_example = create_majority_vote_training_example()\n",
    "    # change training example used as needed\n",
    "    apply_one_shot_per_annotator(i + 1, data, create_majority_vote_training_example())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
